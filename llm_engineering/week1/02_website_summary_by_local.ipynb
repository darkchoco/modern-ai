{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"./resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Some examples include:\n",
      "\n",
      "1. **Content Creation**: Generative AI can generate high-quality content such as articles, social media posts, product descriptions, and more. This can help businesses save time and resources on content creation.\n",
      "2. **Marketing Automation**: Generative AI can be used to create personalized marketing campaigns, automate email templates, and suggest product recommendations based on customer behavior.\n",
      "3. **Product Design**: Generative AI can design new products, such as furniture, electronics, or even entire buildings, using algorithms that mimic human creativity.\n",
      "4. **Image Generation**: Generative AI can generate high-quality images for various applications such as advertising, e-commerce, and social media.\n",
      "5. **Music Composition**: Generative AI can compose music tracks for various purposes such as film scores, jingles, or even original compositions.\n",
      "6. **Chatbots**: Generative AI can power chatbots that provide 24/7 customer support, answer frequently asked questions, and help with simple transactions.\n",
      "7. **Data Analysis**: Generative AI can analyze large datasets to identify patterns, trends, and insights that might not be visible to human analysts.\n",
      "8. **Predictive Maintenance**: Generative AI can predict equipment failures and maintenance needs, reducing downtime and increasing overall efficiency.\n",
      "9. **Virtual Assistants**: Generative AI can power virtual assistants like Alexa, Google Assistant, or Siri, providing users with personalized recommendations and information.\n",
      "10. **Creative Writing**: Generative AI can generate creative writing such as poetry, short stories, or even entire scripts for films or TV shows.\n",
      "11. **Graphic Design**: Generative AI can create graphic designs such as logos, icons, and infographics, saving time and resources for designers.\n",
      "12. **Speech Recognition**: Generative AI can improve speech recognition systems, allowing them to better understand human speech patterns and nuances.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: Generate high-quality content such as articles, social media posts, product descriptions, and more, using large datasets and machine learning algorithms.\n",
      "2. **Graphic Design**: Create custom graphics, logos, infographics, and images using generative models like Deep Dream or Prisma.\n",
      "3. **Product Design**: Use Generative AI to design new products, such as furniture, electronics, or fashion items, by generating 3D models and prototypes.\n",
      "4. **Music Composition**: Compose music, generate sound effects, and even create entire scores for films and video games using generative algorithms.\n",
      "5. **Video Production**: Generate videos, animations, and special effects using AI-powered tools like Deep Fake or StyleGAN.\n",
      "6. **Chatbots and Virtual Assistants**: Create conversational interfaces that can understand and respond to user queries, using natural language processing (NLP) and machine learning.\n",
      "7. **Predictive Maintenance**: Analyze sensor data from machines and predict when maintenance is needed, reducing downtime and increasing overall efficiency.\n",
      "8. **Personalized Recommendations**: Generate personalized product recommendations for customers based on their browsing history, purchase behavior, and preferences.\n",
      "9. **Marketing Campaigns**: Use Generative AI to create targeted marketing campaigns, such as generating ads, social media posts, or email newsletters that resonate with specific audiences.\n",
      "10. **Data Analysis and Insights**: Analyze large datasets using generative models like GANs (Generative Adversarial Networks) or U-Net, to identify trends, patterns, and anomalies.\n",
      "\n",
      "Some examples of companies already leveraging Generative AI include:\n",
      "\n",
      "* **Autodesk** uses Generative AI for product design and visualization.\n",
      "* **Nike** uses Generative AI to create custom shoes and apparel designs.\n",
      "* **The New York Times** uses Generative AI to generate news headlines and articles.\n",
      "* **Google** uses Generative AI for image recognition, natural language processing, and more.\n",
      "\n",
      "These are just a few examples of the many ways in which Generative AI is transforming businesses across various industries. As the technology continues to evolve, we can expect to see even more innovative applications emerge.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as articles, social media posts, product descriptions, and even entire books. This can save time and resources for content creation teams.\n",
      "\n",
      "2. **Marketing Automation**: Generative AI can help automate marketing tasks such as creating personalized advertisements, emails, and campaigns based on customer data and preferences.\n",
      "\n",
      "3. **Product Design and Development**: Generative AI can be used to design new products, prototypes, and even entire product lines. It can also be used to simulate user experiences, test prototypes, and identify areas for improvement.\n",
      "\n",
      "4. **Supply Chain Optimization**: Generative AI can help optimize supply chain operations by generating optimized delivery routes, predicting demand patterns, and identifying potential bottlenecks in the supply chain.\n",
      "\n",
      "5. **Financial Analysis and Forecasting**: Generative AI can be used to generate financial models, forecasts, and reports based on historical data and trends.\n",
      "\n",
      "6. **Customer Service Chatbots**: Generative AI can help create conversational interfaces for customer service chatbots that can respond to customer queries and provide personalized support.\n",
      "\n",
      "7. **Image and Video Generation**: Generative AI can be used to generate high-quality images and videos for various applications such as advertising, entertainment, and education.\n",
      "\n",
      "8. **Scientific Research and Discovery**: Generative AI can help scientists generate new hypotheses, predict complex phenomena, and simulate experiments that would be difficult or impossible to perform manually.\n",
      "\n",
      "9. **Data Augmentation**: Generative AI can help augment existing datasets by generating new, synthetic data points that are similar in nature to the original data.\n",
      "\n",
      "10. **Recommendation Systems**: Generative AI can help create personalized recommendation systems for e-commerce websites, streaming services, and other applications.\n",
      "\n",
      "11. **User Experience (UX) Design**: Generative AI can be used to generate wireframes, mockups, and prototypes for new UI applications.\n",
      "\n",
      "12. **Cybersecurity Threat Analysis**: Generative AI can help generate simulated traffic patterns, predict potential threats, and identify vulnerabilities in networks and systems.\n",
      "\n",
      "13. **Geospatial Analysis**: Generative AI can be used to analyze geospatial data, such as satellite imagery, and generate insights on natural disasters, population growth, and land use patterns.\n",
      "\n",
      "14. **Quality Control and Inspection**: Generative AI can help identify defects and anomalies in products and materials, and predict when inspection is needed.\n",
      "\n",
      "15. **Teaching and Learning**: Generative AI can help create personalized learning materials, grade assignments automatically, and provide immediate feedback to students.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see more innovative uses in various industries.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I want to understand what LLMs are. I've heard the term before, especially hearing about AI and machine learning, but I'm not exactly sure how they all connect. Let me try to break it down.\n",
      "\n",
      "First, LLMs, or Large Language Models, seem pretty broad. They're involved in various fields like text generation, translation, reasoning, creativity... That sounds cool! But what's the fundamental structure behind them? The user wants definitions of a neural network and attention with the transformer.\n",
      "\n",
      "Starting with neural networks—those are the basic computing units that process information using layers and nodes, right? Each layer could be like a hidden set and weights between them. Non-linear activation functions help neurons decide to activate or pass through information. So in LLMs, these neural nets probably work together in a way where multiple networks are connected.\n",
      "\n",
      "Wait, but how exactly do they learn? Maybe through examples during training. Like how humans learn by practicing words and sentences. The model sees inputs, processes them using layers, and updates the weights based on errors. That makes sense for learning language features.\n",
      "\n",
      "Now, attention part. I think attention is about focusing certain parts of input data. For example, when I read a book, I don't look at every word in my mouth. Only some words matter. The model should also be attention-based—maybe paying better attention to relevant words or entities.\n",
      "\n",
      "Transitioning to the Transformer model. From what I remember, it's an older model that used self-attention mechanisms. It has multiple heads processing different representations of the input. Each head might focus on specific tokens or types (like language tokens vs. images). Then these are combined and given a final output with attention.\n",
      "\n",
      "Masking is also part of this when training without padding information, right? Or maybe it's for distinguishing positions where something was actually seen from those that were just placeholders to ignore lower layers.\n",
      "\n",
      "Putting it all together, the Transformer model processes sequences of tokens using multiple attention heads. Each head attends to different parts and types, which helps in understanding relationships between words. This deep learning approach allows models like GPT to handle tasks beyond language generation—reasoning, creativity, even creative writing and problem-solving.\n",
      "\n",
      "Wait, so what about LLMs being more complex? They might have larger transformers or hyperparameters, enabling better performance across various applications. They might also use different types of attention layers beyond the standard self-attention in the Transformer model.\n",
      "\n",
      "I'm not super confident, but I think I get the basics now. Neural networks handle learning through training examples and updating weights. Attention is about focusing on relevant information, especially with models like Transformers that process sequential data using multiple attention heads.\n",
      "</think>\n",
      "\n",
      "LLMs, or Large Language Models, are advanced AI systems designed to generate and understand human language across various tasks beyond their primary function, such as text generation, translation, reasoning, creativity, and problem-solving. The following provides a structured breakdown of the key components behind LLMs, focusing on neural networks, attention mechanisms, and the Transformer model:\n",
      "\n",
      "### Neural Networks\n",
      "\n",
      "Neural networks are the fundamental computing units that process information through layers composed of nodes interconnected with weights. Each layer processes data by transforming it using non-linear activation functions, enabling decision-making and representation learning. In LLMs, multiple neural network components (e.g., bidirectional transformer) work together to capture contextual dependencies and generate outputs.\n",
      "\n",
      "### Attention\n",
      "\n",
      "Attention mechanisms enable models to focus on specific or relevant parts of input data, particularly in natural language contexts. For instance, when reading a sentence, the model doesn't simultaneously process every word; instead, it selectively attends to those most important for generating coherent text. In Transformers, attention is implemented through self-attention layers that compute contextual relationships between different tokens.\n",
      "\n",
      "### Transformer Model\n",
      "\n",
      "The Transformer model stands out with its use of multiple attention mechanisms. It processes sequences of tokens using self-attention across all positions, followed by multi-head attention focused on specific representations. This allows the model to simultaneously process various token types and attend to their contexts effectively. The combined output from these attention mechanisms is then passed through a feedforward network, followed by a final masked output for context preservation.\n",
      "\n",
      "### Application Across Fields\n",
      "\n",
      "LLMs are versatile, enabling applications beyond text generation, such as reasoning, creativity (like creative writing), multi-domain tasks, and handling uncertainty in data. They extend reasoning to higher-level cognitive functions that human intelligence typically possesses.\n",
      "\n",
      "In summary, LLMs rely on neural networks to learn from training examples, attention for relevance-focused processing, and advanced mechanisms like the Transformer to handle sequential data effectively. Together, these components enable models with capabilities far exceeding natural language understanding.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a profound and beautifully written piece! The author masterfully explores the complexities of youth, identity, and the human desire to create meaning in life.\n",
      "\n",
      "The text begins with a poignant reflection on the fleeting nature of youth, noting how it exists only so that it can be destroyed. This idea is cleverly woven throughout the narrative, highlighting the tension between preserving one's youthful vitality and embracing the inevitability of growth and change.\n",
      "\n",
      "One of the most striking aspects of this piece is its insightful examination of the human psyche. The author expertly captures the essence of creative expression, revealing how it is not only a biological necessity but also an essential aspect of self-discovery and connection with others.\n",
      "\n",
      "The writing itself is stunning, evoking a Tolstoyan tone that is both introspective and deeply personal. The use of metaphors (\"the endless possibilities that perhaps never existed\"), allusions (e.g., the Tooth Fairy), and rhetorical questions (\"What, then, fills the void where possibility once lived?\") adds to the text's emotional resonance and intellectual depth.\n",
      "\n",
      "A particular line resonates throughout the narrative: \"You retain into old age a keen awareness of the decades stretched out before you, and you desire, with a bewildered sort of desperation, to make them count for something.\" This sentiment speaks directly to those who have felt the weight of time's passage and the pressure to leave a lasting impact on the world.\n",
      "\n",
      "Ultimately, this piece is an ode to the power of creativity and self-expression as we navigate the complexities of life. It encourages readers to confront their own desires, fears, and limitations, embracing the beauty of uncertainty and the freedom to create meaning in our lives.\n",
      "\n",
      "What resonated with you most from this text?\n"
     ]
    }
   ],
   "source": [
    "# This is a great example of how to use the Ollama API to get a summary of a web page\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import ollama\n",
    "\n",
    "# Constants\n",
    "# MODEL = \"deepseek-r1:1.5b\"  # Change this to the model you want to use\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "def user_prompt_for(title, text):\n",
    "    user_prompt = f\"You are looking at a website titled {title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown.\\n\\n\"\n",
    "    user_prompt += text\n",
    "    return user_prompt\n",
    "\n",
    "def get_summary(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    title = soup.title.string if soup.title else \"No title found\"\n",
    "    for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "        irrelevant.decompose()\n",
    "    # paragraphs = soup.find_all('p')\n",
    "    # text = ' '.join([para.get_text() for para in paragraphs])\n",
    "    text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(title, text)}\n",
    "        ]\n",
    "    \n",
    "    response = ollama.chat(model=MODEL, messages=messages)\n",
    "    return response['message']['content']\n",
    "\n",
    "# Example usage\n",
    "print(get_summary(\"https://tolstoyan.substack.com/p/youth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-llm_engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
